---
title: "Final Project EDA"
authors: "Anna Livingstone Nate Groves"
date: "Fall 2025"
output:
  pdf_document:
    number_sections: no
    toc: false
    toc_depth: 1
  html_document:
    df_print: paged
    number_sections: no
    toc: false
    toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(corrplot)
library(car)
libraries <- read_csv("../data/libraries.csv")
```

Define functions so we can remove outliers from training data.
```{r}
# Function to remove outliers using the IQR rule
remove_outliers <- function(x) {
  if (is.numeric(x) && length(unique(na.omit(x))) > 2) {  # skip binary
    q1 <- quantile(x, 0.25, na.rm = TRUE)
    q3 <- quantile(x, 0.75, na.rm = TRUE)
    iqr <- q3 - q1
    lower <- q1 - 1.5 * iqr
    upper <- q3 + 1.5 * iqr
    x[x < lower | x > upper] <- NA  # mark outliers
  }
  return(x)
}

# Columns to ignore
ignore_cols <- c("Bookmobiles", "Branch Library")

# Apply only to numeric, non-binary, and not ignored columns
libraries <- libraries %>%
  mutate(across(
    .cols = where(is.numeric) & !all_of(ignore_cols),
    .fns = remove_outliers
  )) %>%
  drop_na()

```

Libraries is already the training set.
We can start by using a linear model:
```{r}
full.library.model <- lm(`Total Circulation` ~ ., data = libraries)
summary(full.library.model)
```
The full library model has lots of predictors from the dummy variables of state, 
but we can probably remove some of the predictors.




