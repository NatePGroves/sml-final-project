var.est1 <- function(x){ return( min(x) ) }
var.JK <- jackknife(frequencies, var.est1)
cat("The initial estimate is (MLE, biased): ", var.est1(frequencies))
cat("The Jackknife estimate is: ", var.est1(frequencies) - var.JK$jack.bias)
library(bootstrap)
frequencies <- c(102, 115, 127, 127, 162, 180, 184, 205, 239, 240)
var.est1 <- function(x){ return( min(x) ) }
var.JK <- jackknife(frequencies, var.est1)
cat("The initial estimate is (MLE, biased): ", var.est1(frequencies))
cat("The Jackknife estimate is: ", var.est1(frequencies) - var.JK$jack.bias)
library(MASS)
mean(Boston$medv)
sd(mu_hat)
mu_hat<- mean(Boston$medv)
sd(mu_hat)
sdd(Boston$medv)
sd(Boston$medv)
B <- 2000
n <- length(Boston$medv)
med.bootsample <- rep(NA, B)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
hist(med.bootsample)
B <- 2000
n <- length(Boston$medv)
med.bootsample <- rep(NA, B)
set.seed(5678)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
hist(med.bootsample)
sd(med.bootsample)
B <- 2000
n <- length(Boston$medv)
med.bootsample <- rep(NA, B)
set.seed(5678)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
sd(med.bootsample)
B <- 2000
n <- length(Boston$medv)
med.bootsample <- rep(NA, B)
set.seed(5678)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
sd(med.bootsample)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
sd(med.bootsample)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
sd(med.bootsample)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
sd(med.bootsample)
sd(mean(Boston$medv))
n <- length(Boston$medv)
se <- sd(Boston$medv)/n
The standard error of $\hat\mu$ is `se`.
se
se <- sd(Boston$medv)/sqrt(n)
se <- sd(Boston$medv)/sqrt(n)
se
se_boot <- sd(bootsample)/sqrt(n)
se_boot
B <- 2000
med.bootsample <- rep(NA, B)
set.seed(5678)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
B <- 2000
med.bootsample <- rep(NA, B)
set.seed(5678)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
B <- 2000
med.bootsample <- rep(NA, B)
set.seed(5678)
for (k in 1:B){
bootsample <- sample(Boston$medv, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
se_boot <- sd(bootsample)/sqrt(n)
se_boot
t.test(Boston$medv)
2*0.4118526
22.53281-0.8237052
22.53281+0.8237052
summary(med.bootsample)
conf.level <- 0.95 # 95% CI, alpha = 0.05.
alp <- 1 - conf.level
bootCI <- quantile(med.bootsample, c( alp/2, 1-alp/2))
bootCI.Normal <- mean(med.bootsample) + c(-1, 1)*qnorm(1-alp/2, mean=0, sd=1)*sd(med.bootsample)
rbind(bootCI, bootCI.Normal)
median(Boston$medv)
summary(med.bootsample)
median(Boston$medv)
median(Boston$medv)
boot.ci(bootsample, type=c("norm"))
library(boot)
boot.ci(bootsample, type=c("norm"))
boot.ci(bootsample, type=c("norm"))
boot(data=Boston$medv, statistic = med.fn, R = 8000)
22.53281
library(boot)
med.fn <- function(x, inds){
return(median(x[inds]))
}
boot(data=Boston$medv, statistic = med.fn, R = 8000)
boot.ci(bootsample, type=c("norm"))
medv.boot <- boot(data=Boston$medv, statistic = med.fn, R = 8000)
boot.ci(medv.boot, type=c("norm"))
med.fn <- function(x, inds){
return(median(x[inds]))
}
medv.boot <- boot(data=Boston$medv, statistic = med.fn, R = 8000)
boot.ci(medv.boot, type=c("norm"))
1+3+4.5+6.5
15/4
2-3.75
3/3.75
3-3.75
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
data(birthwt)
library(MASS)
data(birthwt)
# Do NOT use variable bwt (last column) in this problem.
midterm.data <- birthwt[, -ncol(birthwt)]
# Declare categorical predictors.
midterm.data$race <- factor(midterm.data$race, labels=c("white", "black", "other"))
midterm.data$smoke <- factor(midterm.data$smoke, labels=c("NoSmoking", "Smoking"))
midterm.data$ht <- factor(midterm.data$ht, labels=c("NoHypertesion", "Hypertesion"))
midterm.data$ui <- factor(midterm.data$ui, labels=c("NoUI", "UI"))
# Quick review
summary(midterm.data)
model1 <- glm(low ~ age + lwt + race + smoke + ptl + ht + ui + ftv, data=birthwt, family=binomial)
model1
# Use the last 4 digits of your student ID to set seed.
set.seed(1019)
model1 <- glm(low ~ age + lwt + race + smoke + ptl + ht + ui + ftv, data=birthwt, family=binomial)
model1
# Use the last 4 digits of your student ID to set seed.
set.seed(1019)
model1 <- glm(low ~ age + lwt + race + smoke + ptl + ht + ui + ftv, data=birthwt, family=binomial)
model1
# Use the last 4 digits of your student ID to set seed.
set.seed(1019)
model1 <- glm(low ~ age + lwt + race + smoke + ptl + ht + ui + ftv, data=midterm.data, family=binomial)
model1
model2 <- step(model1)
model1 <- glm(low ~ age + lwt + race + smoke + ptl + ht + ui + ftv, data=midterm.data, family=binomial)
model1
model2 <- step(model1)
model2 <- step(model1)
model2 <- step(model1)
summary(model2)
model2 <- step(model1)
summary(model2)
roc.analysis <-function (object, newdata = NULL, newplot=TRUE)
{
if (is.null(newdata)) {
pi.tp <- object$fitted[object$y == 1]
pi.tn <- object$fitted[object$y == 0]
}
else {
pi.tp <- predict(object, newdata, type = "response")[newdata$y == 1]
pi.tn <- predict(object, newdata, type = "response")[newdata$y == 0]
}
pi.all <- sort(c(pi.tp, pi.tn))
sens <- rep(1, length(pi.all)+1)
specc <- rep(1, length(pi.all)+1)
for (i in 1:length(pi.all)) {
sens[i+1] <- mean(pi.tp >= pi.all[i], na.rm = T)
specc[i+1] <- mean(pi.tn >= pi.all[i], na.rm = T)
}
npoints <- length(sens)
area <- sum(0.5 * (sens[-1] + sens[-npoints]) * (specc[-npoints] -
specc[-1]))
lift <- (sens - specc)[-1]
cutoff <- pi.all[lift == max(lift)][1]
sensopt <- sens[-1][lift == max(lift)][1]
specopt <- 1 - specc[-1][lift == max(lift)][1]
par(pty="s")
if (newplot){
plot(specc, sens, xlim = c(0, 1), ylim = c(0, 1), type = "s",
xlab = "FPR = 1-specificity", ylab = "TPR = sensitivity", main="ROC")
abline(0, 1)
}
else lines(specc, sens, type="s", lty=2, col=2)
list(pihat=as.vector(pi.all), sens=as.vector(sens[-1]),
spec=as.vector(1-specc[-1]), area = area, cutoff = cutoff,
sensopt = sensopt, specopt = specopt)
}
set.seed(1019)
train.pct <- 0.70
Z <- sample(nrow(midterm.data), train.pct*nrow(midterm.data))
training <- midterm.data[Z]
training <- midterm.data[Z]
Z <- sample(nrow(midterm.data), train.pct*nrow(midterm.data))
training <- midterm.data[Z]
testing <- midterm.data[-Z]
testing
midterm.data
training <- midterm.data[Z,]
testing <- midterm.data[-Z,]
training
train.ROC <- roc.analysis(model1)
low.testing$y <- 1*(testing$lwt == 1)
testing$y <- 1*(testing$lwt == 1)
test.ROC <- roc.analysis(model1, newdata=depr.testing, newplot=F)
test.ROC <- roc.analysis(model1, newdata=testing, newplot=F)
set.seed(1019)
train.pct <- 0.70
Z <- sample(nrow(midterm.data), train.pct*nrow(midterm.data))
training <- midterm.data[Z,]
testing <- midterm.data[-Z,]
train.ROC <- roc.analysis(model1)
testing$y <- 1*(testing$lwt == 1)
test.ROC <- roc.analysis(model1, newdata=testing, newplot=F)
train.ROC <- roc.analysis(model1)
train.ROC2 <- roc.analysis(model2)
train.ROC1 <- roc.analysis(model1)
train.ROC2 <- roc.analysis(model2)
train.ROC1 <- roc.analysis(model1)
train.ROC2 <- roc.analysis(model2)
train.ROC2 <- roc.analysis(model2)
train.ROC1$area
train.ROC2$area
library(boot)
cv.error <- cv.glm(data=midterm.data, glmfit=model1)
cv.error$delta
cv.error1
cv.error
set.seed(1019)
cv.error1 <- cv.glm(data=midterm.data, glmfit=model1)
cv.error1$delta
cv.error2 <- cv.glm(data=midterm.data, glmfit=model2)
cv.error2$delt
model3 <- qda(low~age+lwt+ptl+ftv, data=midterm.data)
summary(model3)
B <- 8000 # number of Bootstrap samples
n <- length(midterm.data$low)
med.bootsample <- rep(NA, B)
for (k in 1:B){
bootsample <- sample(midterm.data$low, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
conf.level <- 0.95 # 95% CI, alpha = 0.05.
alp <- 1 - conf.level
bootCI <- quantile(med.bootsample, c( alp/2, 1-alp/2))
bootCI.Normal <- mean(med.bootsample) + c(-1, 1)*qnorm(1-alp/2, mean=0, sd=1)*sd(med.bootsample)
rbind(bootCI, bootCI.Normal
rbind(bootCI, bootCI.Normal)
B <- 8000 # number of Bootstrap samples
n <- length(midterm.data$low)
med.bootsample <- rep(NA, B)
for (k in 1:B){
bootsample <- sample(midterm.data$low, size=n, replace = TRUE)
}
conf.level <- 0.95 # 95% CI, alpha = 0.05.
alp <- 1 - conf.level
bootCI <- quantile(med.bootsample, c( alp/2, 1-alp/2))
B <- 8000 # number of Bootstrap samples
n <- length(midterm.data$low)
med.bootsample <- rep(NA, B)
for (k in 1:B){
bootsample <- sample(midterm.data$low, size=n, replace = TRUE)
med.bootsample[k] <- median(bootsample)
}
conf.level <- 0.95 # 95% CI, alpha = 0.05.
alp <- 1 - conf.level
bootCI <- quantile(med.bootsample, c( alp/2, 1-alp/2))
bootCI.Normal <- mean(med.bootsample) + c(-1, 1)*qnorm(1-alp/2, mean=0, sd=1)*sd(med.bootsample)
rbind(bootCI, bootCI.Normal)
bootCI <- quantile(med.bootsample, c( alp/2, 1-alp/2))
bootCI
setwd("C:/Users/18582/OneDrive/Desktop/College/Fall 2025/Statistical Machine Learning/sml-final-project")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(corrplot)
library(car)
libraries <- read_csv("../data/libraries.csv")
numeric_libaries <- libraries %>%
select(where(is.numeric))
full_correlation_matrix <- cor(numeric_libaries)
y_cor_matrix<- full_correlation_matrix[, "Total Circulation", drop = FALSE]
y_cor_matrix[order(abs(y_cor_matrix[, 1]), decreasing = TRUE), , drop = FALSE]
model <- lm(`Total Circulation` ~ ., data = numeric_libaries)
vif(model)
for (col in names(numeric_libaries)) {
hist(
numeric_libaries[[col]],
main = paste("Histogram of", col),
xlab = col,
col = "skyblue",
border = "white"
)
}
# Function to remove outliers using the IQR rule
remove_outliers <- function(x) {
if (is.numeric(x) && length(unique(na.omit(x))) > 2) {  # skip binary
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
x[x < lower | x > upper] <- NA  # mark outliers
}
return(x)
}
# Columns to ignore
ignore_cols <- c("Bookmobiles", "Branch Library")
# Apply only to numeric, non-binary, and not ignored columns
libraries_no_outliers <- libraries_filtered %>%
mutate(across(
.cols = where(is.numeric) & !all_of(ignore_cols),
.fns = remove_outliers
)) %>%
drop_na()
# Function to remove outliers using the IQR rule
remove_outliers <- function(x) {
if (is.numeric(x) && length(unique(na.omit(x))) > 2) {  # skip binary
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
x[x < lower | x > upper] <- NA  # mark outliers
}
return(x)
}
# Columns to ignore
ignore_cols <- c("Bookmobiles", "Branch Library")
# Apply only to numeric, non-binary, and not ignored columns
libraries_no_outliers <- libraries_filtered %>%
mutate(across(
.cols = where(is.numeric) & !all_of(ignore_cols),
.fns = remove_outliers
)) %>%
drop_na()
libraries_no_outliers_numeric <- libraries_no_outliers %>% select(where(is.numeric))
# Function to remove outliers using the IQR rule
remove_outliers <- function(x) {
if (is.numeric(x) && length(unique(na.omit(x))) > 2) {  # skip binary
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
x[x < lower | x > upper] <- NA  # mark outliers
}
return(x)
}
# Columns to ignore
ignore_cols <- c("Bookmobiles", "Branch Library")
# Apply only to numeric, non-binary, and not ignored columns
libraries_no_outliers <- libraries_filtered %>%
mutate(across(
.cols = where(is.numeric) & !all_of(ignore_cols),
.fns = remove_outliers
)) %>%
drop_na()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(corrplot)
library(car)
libraries <- read_csv("../data/libraries.csv")
numeric_libaries <- libraries %>%
select(where(is.numeric))
full_correlation_matrix <- cor(numeric_libaries)
y_cor_matrix<- full_correlation_matrix[, "Total Circulation", drop = FALSE]
y_cor_matrix[order(abs(y_cor_matrix[, 1]), decreasing = TRUE), , drop = FALSE]
model <- lm(`Total Circulation` ~ ., data = numeric_libaries)
vif(model)
for (col in names(numeric_libaries)) {
hist(
numeric_libaries[[col]],
main = paste("Histogram of", col),
xlab = col,
col = "skyblue",
border = "white"
)
}
# Function to remove outliers using the IQR rule
remove_outliers <- function(x) {
if (is.numeric(x) && length(unique(na.omit(x))) > 2) {  # skip binary
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower <- q1 - 1.5 * iqr
upper <- q3 + 1.5 * iqr
x[x < lower | x > upper] <- NA  # mark outliers
}
return(x)
}
# Columns to ignore
ignore_cols <- c("Bookmobiles", "Branch Library")
# Apply only to numeric, non-binary, and not ignored columns
libraries_no_outliers <- libraries %>%
mutate(across(
.cols = where(is.numeric) & !all_of(ignore_cols),
.fns = remove_outliers
)) %>%
drop_na()
libraries_no_outliers_numeric <- libraries_no_outliers %>% select(where(is.numeric))
for (col in names(libraries_no_outliers_numeric)) {
hist(
libraries_no_outliers_numeric[[col]],
main = paste("Histogram of", col),
xlab = col,
col = "skyblue",
border = "white"
)
}
categorical_data <- libraries %>% select(!where(is.numeric))
# Loop through each categorical column and plot
for (col in names(categorical_data)) {
ggplot(categorical_data, aes_string(x = col)) +
geom_bar(fill = "steelblue", color = "white") +
theme_minimal() +
labs(
title = paste("Bar Chart of", col),
x = col,
y = "Count"
) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1)
) -> p
print(p)
}
